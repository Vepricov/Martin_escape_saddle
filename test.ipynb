{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d2e12e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 9])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([[[1, 2, 3], [4, 5, 6], [7, 8, 9]],\n",
    "                  [[1, 2, 3], [4, 5, 6], [7, 8, 9]]])\n",
    "a.transpose_(0, 1)\n",
    "a = a.contiguous()\n",
    "a = a.view(2, -1)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ca3c2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1.45, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46f18267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 1, '2': 2, '3': 4, '4': 3}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {\"1\" : 1, \"2\" : 2}\n",
    "b = {\"3\" : 4, \"4\" : 3}\n",
    "a | b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ed926c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e520353a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mType:\u001b[0m        ArgumentParser\n",
      "\u001b[0;31mString form:\u001b[0m ArgumentParser(prog='ipykernel_launcher.py', usage=None, description=None, formatter_class=<class 'argparse.HelpFormatter'>, conflict_handler='error', add_help=True)\n",
      "\u001b[0;31mFile:\u001b[0m        ~/miniconda3/lib/python3.10/argparse.py\n",
      "\u001b[0;31mDocstring:\u001b[0m  \n",
      "Object for parsing command line strings into Python objects.\n",
      "\n",
      "Keyword Arguments:\n",
      "    - prog -- The name of the program (default:\n",
      "        ``os.path.basename(sys.argv[0])``)\n",
      "    - usage -- A usage message (default: auto-generated from arguments)\n",
      "    - description -- A description of what the program does\n",
      "    - epilog -- Text following the argument descriptions\n",
      "    - parents -- Parsers whose arguments should be copied into this one\n",
      "    - formatter_class -- HelpFormatter class for printing help messages\n",
      "    - prefix_chars -- Characters that prefix optional arguments\n",
      "    - fromfile_prefix_chars -- Characters that prefix files containing\n",
      "        additional arguments\n",
      "    - argument_default -- The default value for all arguments\n",
      "    - conflict_handler -- String indicating how to handle conflicts\n",
      "    - add_help -- Add a -h/-help option\n",
      "    - allow_abbrev -- Allow long options to be abbreviated unambiguously\n",
      "    - exit_on_error -- Determines whether or not ArgumentParser exits with\n",
      "        error info when an error occurs"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"kind\", type=str,\n",
    "                    help=\"Kind of experiment: single-model, hidden-loop or hidden-sample\")\n",
    "?parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1b10b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `sklearn.datasets` not found.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_svmlight_file, make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7e913e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegressionModel(\n",
      "  (linear): Linear(in_features=3, out_features=2, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class LinearRegressionModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim=3, output_dim=1):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim, dtype=X.dtype, bias=False)\n",
    "    def forward(self, x):\n",
    "        y = self.linear(x)\n",
    "        return y\n",
    "    \n",
    "model = LinearRegressionModel(input_dim=X.shape[1], output_dim=y.shape[1])\n",
    "print(model)\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "565b190b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3128, 0.3760, 0.1549],\n",
       "        [0.3760, 0.5122, 0.2396],\n",
       "        [0.1549, 0.2396, 0.1242]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q, L, _ = torch.svd(model.linear.weight.T @ model.linear.weight)\n",
    "Q @ torch.diag(L) @ Q.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e9ff6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3128, 0.3760, 0.1549],\n",
       "        [0.3760, 0.5122, 0.2396],\n",
       "        [0.1549, 0.2396, 0.1242]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.linear.weight.T @ model.linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b572be53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import soap\n",
    "import new_soap\n",
    "reload(soap)\n",
    "reload(new_soap)\n",
    "\n",
    "model = LinearRegressionModel(input_dim=X.shape[1], output_dim=y.shape[1])\n",
    "# optimizer = soap.SOAP(model.parameters(), \n",
    "#                  lr=3e-3, \n",
    "#                  betas=(.95, .95), \n",
    "#                  weight_decay=.01, \n",
    "#                  precondition_frequency=10)\n",
    "optimizer = new_soap.NEW_SOAP(model.parameters(), \n",
    "                 lr=3e-3, \n",
    "                 beta=.95, \n",
    "                 weight_decay=.01, \n",
    "                 precondition_frequency=10)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "af7dfcb2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'beta'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      8\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m----> 9\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m num_verbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: loss \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch, loss\u001b[38;5;241m.\u001b[39mitem()))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/optim/optimizer.py:484\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    480\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m             )\n\u001b[0;32m--> 484\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Papers/Martin_escape_saddle_point/zalupa.py:129\u001b[0m, in \u001b[0;36mstep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    124\u001b[0m if \"exp_avg\" not in state:\n\u001b[1;32m    125\u001b[0m     # Exponential moving average of gradient values\n\u001b[1;32m    126\u001b[0m     state[\"exp_avg\"] = torch.zeros_like(grad)\n\u001b[1;32m    128\u001b[0m # if 'Q' not in state:\n\u001b[0;32m--> 129\u001b[0m #     self.init_preconditioner(\n\u001b[1;32m    130\u001b[0m #         grad,\n\u001b[1;32m    131\u001b[0m #         state,\n\u001b[1;32m    132\u001b[0m #         precondition_frequency=group['precondition_frequency'],\n\u001b[1;32m    133\u001b[0m #         precondition_1d=group['precondition_1d'],\n\u001b[1;32m    134\u001b[0m #         max_precond_dim=group['max_precond_dim'],\n\u001b[1;32m    135\u001b[0m #         merge_dims=group[\"merge_dims\"],\n\u001b[1;32m    136\u001b[0m #     )\n\u001b[1;32m    137\u001b[0m #     self.update_preconditioner(grad, state,\n\u001b[1;32m    138\u001b[0m #                                max_precond_dim=group['max_precond_dim'],\n\u001b[1;32m    139\u001b[0m #                                merge_dims=group[\"merge_dims\"],\n\u001b[1;32m    140\u001b[0m #                                precondition_1d=group[\"precondition_1d\"])\n\u001b[1;32m    141\u001b[0m #     continue # first step is skipped so that we never use the current gradients in the projection.\n\u001b[1;32m    142\u001b[0m \n\u001b[1;32m    143\u001b[0m # Projecting gradients to the eigenbases of Shampoo's preconditioner \n\u001b[1;32m    144\u001b[0m # i.e. projecting to the eigenbases of matrices in state['GG']\n\u001b[1;32m    145\u001b[0m # print(\"$\"*60, \"\\ngrad.T@ grad and grad@ grad.T:\")\n\u001b[1;32m    146\u001b[0m # print(grad@grad.T)\n\u001b[1;32m    147\u001b[0m # print(grad.T@grad)\n\u001b[1;32m    148\u001b[0m # print(\"$\"*60, \"\\nstate[GG]:\")\n\u001b[1;32m    149\u001b[0m # for mat in state['GG']:\n\u001b[1;32m    150\u001b[0m #     print(mat)\n\u001b[1;32m    151\u001b[0m # print(\"$\"*60, \"\\nstate[Q]:\")\n\u001b[1;32m    152\u001b[0m # for mat in state['Q']:\n\u001b[1;32m    153\u001b[0m #     print(mat, \"\\n\", mat.T @ mat)\n\u001b[1;32m    154\u001b[0m grad_projected = self.project(grad, state, merge_dims=group[\"merge_dims\"], \n\u001b[1;32m    155\u001b[0m                               max_precond_dim=group['max_precond_dim'])\n\u001b[1;32m    157\u001b[0m # Decay the first and second moment running average coefficient\n\u001b[1;32m    158\u001b[0m # In-place operations to update the averages at the same time\n",
      "\u001b[0;31mKeyError\u001b[0m: 'beta'"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "num_verbose = 1\n",
    "for epoch in range(num_epochs):\n",
    "    pred_y = model(X)\n",
    " \n",
    "    loss = criterion(pred_y, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % num_verbose == 0:\n",
    "        print('Epoch {}: loss {}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75508366",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "martin_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
